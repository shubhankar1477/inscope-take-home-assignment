{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from html_workflow.parser import ExtractItems\n",
    "from utils.text_cleaner import clsCleaner\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "from  bs4 import BeautifulSoup\n",
    "import requests\n",
    "import tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return extraction.extract_items(content=content)\n",
    "\n",
    "def generate_summary_or_document(cik, company_name, json_section, is_inference=False):\n",
    "    if json_section:\n",
    "        summary = get_summarise_text(json_section)\n",
    "        if not is_inference:\n",
    "            return create_document({\"CIK\": cik, \"company_name\": company_name}, summary)\n",
    "        else:\n",
    "            return summary\n",
    "    return None\n",
    "\n",
    "def process_record(record, raw_fillings_dir, is_inference=False):\n",
    "    cik = record['CIK']\n",
    "    company_name = record['Company_Name']\n",
    "    file_path = os.path.join(raw_fillings_dir, cik + '.html')\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        json_section = process_file(file_path)\n",
    "        return generate_summary_or_document(cik, company_name, json_section, is_inference)\n",
    "    return None\n",
    "\n",
    "def create_document(company_metadata,summary):\n",
    "    return Document(page_content=summary,metadata=company_metadata)\n",
    "\n",
    "def get_summarise_text(content_json):\n",
    "    final_text = ''\n",
    "    text_list = clsCleaner.extract_values(content_json,['item_1' , 'item_2','item_5'])\n",
    "    for text in text_list:\n",
    "        # text = clsCleaner.create_half_text(text)\n",
    "        output = query({\"inputs\": f\" {text}\",})\n",
    "        if len(output) > 0 :\n",
    "            final_text = final_text + output[0]['summary_text']\n",
    "    return final_text   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = ExtractItems(\n",
    "        remove_tables=True,\n",
    "        items_to_extract=[\n",
    "\t\t\t\"1\", \"1A\", \"1B\", \"2\", \"5\", \"7\"\n",
    "\t\t],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(cik):\n",
    "    try:\n",
    "        output_json = {\"cluster_companies\":{\"company_name\":[] , \"CIK\" :[] , \"score\":[]}}\n",
    "        company_csv = pd.read_csv(\"comapny_mapping.csv\",dtype={'CIK': str}) \n",
    "        record=company_csv[company_csv['CIK']==str(cik)].to_dict(orient='records')\n",
    "        summary=process_record(record[0],raw_fillings_dir='./data',is_inference=True)\n",
    "        new_db = FAISS.load_local('faiss_index', embeddings)\n",
    "        result = new_db.similarity_search_with_score(summary,k=3)\n",
    "        print(len(result))\n",
    "        for document,score in result:\n",
    "            print(document)\n",
    "            output_json['cluster_companies']['company_name'].append(document.metadata['company_name'])\n",
    "            output_json['cluster_companies']['CIK'].append(document.metadata['CIK'])\n",
    "            output_json['cluster_companies']['score'].append(str(score))\n",
    "            output_json['inference_company_name'] = record[0]['Company_Name']\n",
    "            output_json['inference_CIK'] = record[0]['CIK']\n",
    "            output_json['summary'] = summary\n",
    "        return json.dumps(output_json) \n",
    "    except Exception as e:\n",
    "        return json.dumps(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://686abad61fc6766193.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://686abad61fc6766193.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=inference, inputs=\"text\", outputs=gr.Json(), title=\"Inscope Home Assignment\", description=\"Summarising and Clustering\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
